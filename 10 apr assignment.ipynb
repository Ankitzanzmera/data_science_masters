{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82734aa6",
   "metadata": {},
   "source": [
    "#### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a9d01",
   "metadata": {},
   "source": [
    "We can use Bayes' theorem to calculate the probability of an employee being a smoker given that he/she uses the health insurance plan. Let S represent the event that an employee is a smoker and H represent the event that an employee uses the health insurance plan. Then, we have:\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H)\n",
    "\n",
    "We know that P(H) is the probability of an employee using the health insurance plan, which is given to be 0.70. We also know that P(S) is the probability of an employee being a smoker, which is not given in the problem. However, we can use the information given in the problem to calculate it:\n",
    "\n",
    "P(S) = P(S|H) * P(H) + P(S|H') * P(H')\n",
    "\n",
    "where H' is the event that an employee does not use the health insurance plan. We can assume that P(S|H') is much smaller than P(S|H), since smoking is likely to be correlated with health problems and the use of health insurance. Therefore, we can approximate P(S) as:\n",
    "\n",
    "P(S) â‰ˆ P(S|H) * P(H)\n",
    "\n",
    "Substituting the known values, we get:\n",
    "\n",
    "P(S) = 0.40 * 0.70 = 0.28\n",
    "\n",
    "Now, we can substitute all the known values into Bayes' theorem to get:\n",
    "\n",
    "P(S|H) = 0.40 * 0.70 / 0.70 = 0.40\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.40 or 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b081d",
   "metadata": {},
   "source": [
    "#### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555d899",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two types of Naive Bayes classifiers that are commonly used for text classification tasks. The main difference between the two lies in the way they represent the data.\n",
    "\n",
    "Bernoulli Naive Bayes assumes that each feature (or word) is binary, meaning that it is either present or absent in the document. For example, in a spam classification task, the features could be the presence or absence of certain words in the email. If a particular word is present in the email, its corresponding feature value would be 1, and if it is absent, the value would be 0. Bernoulli Naive Bayes calculates the likelihood of each feature given the class, and uses these probabilities to classify new instances.\n",
    "\n",
    "Multinomial Naive Bayes, on the other hand, assumes that each feature represents a count of the number of times it occurs in the document. For example, in a sentiment analysis task, the features could be the frequency of certain words in a given review. If a particular word occurs twice in the review, its corresponding feature value would be 2. Multinomial Naive Bayes calculates the likelihood of each feature given the class, taking into account the frequency of each feature, and uses these probabilities to classify new instances.\n",
    "\n",
    "In summary, the main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the way they represent the data - binary for Bernoulli and count-based for Multinomial. The choice between the two depends on the specific problem at hand and the characteristics of the data. If the data is binary in nature and the focus is on presence/absence of features, Bernoulli Naive Bayes may be more appropriate. If the data represents frequency counts, Multinomial Naive Bayes may be a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d838b3",
   "metadata": {},
   "source": [
    "#### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8d15e",
   "metadata": {},
   "source": [
    "\n",
    "Bernoulli Naive Bayes assumes that each feature is binary, meaning that it is either present or absent in the document. If a feature is missing (i.e., its value is unknown), it can be treated as if it is absent. This is known as the \"missing-at-random\" assumption, which assumes that the probability of a missing value is independent of the true value of the feature, given the class.\n",
    "\n",
    "In practice, when using Bernoulli Naive Bayes for classification, missing values can be handled by simply ignoring them and treating them as if they were absent. This is because the probability of a missing value occurring in a document is relatively low, and so the impact of missing values on classification accuracy is usually small. However, if missing values occur frequently or are systematically related to the class variable, the model's accuracy may be compromised.\n",
    "\n",
    "In cases where missing values occur frequently or are systematically related to the class variable, more advanced techniques can be used to handle missing values. For example, imputation methods can be used to estimate missing values based on other features in the dataset, or more complex models such as Decision Trees or Random Forests can be used to handle missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a14334",
   "metadata": {},
   "source": [
    "#### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b20674",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. Gaussian Naive Bayes is a probabilistic algorithm that can be used for classification problems where the input features are continuous-valued. In the case of multi-class classification, Gaussian Naive Bayes assumes that the conditional probability distribution of the input features given the class label follows a Gaussian distribution. It then calculates the posterior probability of each class given the input features using Bayes' theorem and chooses the class with the highest probability as the predicted class. One way to handle multi-class classification using Gaussian Naive Bayes is to use the \"one-vs-all\" or \"one-vs-rest\" approach. In this approach, a separate binary classification model is trained for each class label. Each binary classifier predicts whether an input belongs to that class or not. The final prediction is made by selecting the class with the highest probability among all the binary classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97755dd",
   "metadata": {},
   "source": [
    "#### Q5. Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/ datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43c8b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fa442ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...   0.41  \\\n",
       "0     0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "1     0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "2     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "3     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.000   \n",
       "...    ...   ...     ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4595  0.31  0.00    0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4596  0.00  0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.30  0.00    0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4598  0.96  0.00    0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4599  0.00  0.00    0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "       0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0     0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1     0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2     0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3     0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4     0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "...     ...   ...    ...    ...    ...    ...  ...   ... ..  \n",
       "4595  0.232   0.0  0.000  0.000  0.000  1.142    3    88  0  \n",
       "4596  0.000   0.0  0.353  0.000  0.000  1.555    4    14  0  \n",
       "4597  0.718   0.0  0.000  0.000  0.000  1.404    6   118  0  \n",
       "4598  0.057   0.0  0.000  0.000  0.000  1.147    5    78  0  \n",
       "4599  0.000   0.0  0.125  0.000  0.000  1.250    5    40  0  \n",
       "\n",
       "[4600 rows x 58 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./spambase.data')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "368f9bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4600, 57), (4600,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('1',axis = 1)\n",
    "y = df['1']\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e7b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3220, 57), (1380, 57), (3220,), (1380,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=44,test_size=0.3)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90af5b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[778  48]\n",
      " [114 440]]\n",
      "0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91       826\n",
      "           1       0.90      0.79      0.84       554\n",
      "\n",
      "    accuracy                           0.88      1380\n",
      "   macro avg       0.89      0.87      0.88      1380\n",
      "weighted avg       0.88      0.88      0.88      1380\n",
      "\n",
      "Mean of Accuracy of k = 5 Cross validation is 0.8872670807453418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "## BernolluNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "validation  = KFold(n_splits=5)\n",
    "cross_score = np.mean(cross_val_score(BernoulliNB(),X_train,y_train,cv = validation,scoring = 'accuracy'))\n",
    "print(f'Mean of Accuracy of k = 5 Cross validation is {cross_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03fbbcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[684 142]\n",
      " [170 384]]\n",
      "0.7739130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       826\n",
      "           1       0.73      0.69      0.71       554\n",
      "\n",
      "    accuracy                           0.77      1380\n",
      "   macro avg       0.77      0.76      0.76      1380\n",
      "weighted avg       0.77      0.77      0.77      1380\n",
      "\n",
      "Mean of Accuracy of k = 5 Cross validation is 0.7878881987577641\n"
     ]
    }
   ],
   "source": [
    "## BernolluNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "validation  = KFold(n_splits=5)\n",
    "cross_score = np.mean(cross_val_score(MultinomialNB(),X_train,y_train,cv = validation,scoring = 'accuracy'))\n",
    "print(f'Mean of Accuracy of k = 5 Cross validation is {cross_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df031b0",
   "metadata": {},
   "source": [
    "##### In bernoulliNB the accuracy of Model on test data is 0.89 while in Multinomial accuracy of model is 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f7d55",
   "metadata": {},
   "source": [
    "In this particular Dataset BernoulliNB Model Perform Wwll whenever we get this kind of problem we should use this algorithm for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02027f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
