{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397b206c",
   "metadata": {},
   "source": [
    "#### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435511fe",
   "metadata": {},
   "source": [
    "Min-Max scaling is a normalization technique that enables us to scale data in a dataset to a specific range using each feature’s minimum and maximum value.\n",
    "\n",
    "Unlike standard scaling, where data are scaled based on the standard normal distribution(with mean = 0 and standard deviation = 1), the min-max scaler uses each column’s minimum and maximum value to scale the data series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb506d0",
   "metadata": {},
   "source": [
    "MinMaxScaler preserves the shape of the original distribution. It doesn't meaningfully change the information embedded in the original data. Note that MinMaxScaler doesn't reduce the importance of outliers. The default range for the feature returned by MinMaxScaler is 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650936e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.001111\n",
       "1      0.073333\n",
       "2      0.277778\n",
       "3      0.256667\n",
       "4      0.290000\n",
       "         ...   \n",
       "239    0.546667\n",
       "240    0.111111\n",
       "241    0.111111\n",
       "242    0.083333\n",
       "243    0.222222\n",
       "Name: new_tip, Length: 244, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min-max scaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df = sns.load_dataset('tips')\n",
    "minmax = MinMaxScaler()\n",
    "df['new_tip'] = minmax.fit_transform(df[['tip']])\n",
    "df['new_tip']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957971b",
   "metadata": {},
   "source": [
    "#### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b7f79",
   "metadata": {},
   "source": [
    "The Unit Vector technique in feature scaling is a method of scaling features in a dataset by dividing each value in a feature by the Euclidean norm of the feature vector. This technique results in all features having a Euclidean norm (magnitude) of 1, hence the term \"unit vector\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa83584",
   "metadata": {},
   "source": [
    "The unit vector technique differs from Min-Max scaling in that it does not necessarily result in values between 0 and 1, but rather scales the features so that they all have the same magnitude. Min-Max scaling, on the other hand, scales features so that they fall within a specified range, usually between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bd49580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59701077, 0.80223322],\n",
       "       [1.        , 0.        ],\n",
       "       [0.50204711, 0.86484027],\n",
       "       ...,\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75342466, 0.65753425]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('taxis')\n",
    "from sklearn.preprocessing import normalize\n",
    "normalize(df[['distance','tip']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb53c5b",
   "metadata": {},
   "source": [
    "#### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49831c0e",
   "metadata": {},
   "source": [
    "PCA, or Principal Component Analysis, is a technique used for dimensionality reduction in machine learning. The goal of PCA is to identify the most important features, or components, in a dataset, and to project the data onto a lower-dimensional space while retaining as much of the original information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91b9de",
   "metadata": {},
   "source": [
    "PCA works by finding the eigenvectors and eigenvalues of the covariance matrix of the data. The eigenvectors represent the principal components, and the eigenvalues represent the amount of variance in the data explained by each principal component. By keeping only the principal components with the highest eigenvalues, we can reduce the dimensionality of the data while retaining most of the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f189296",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad110f5",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) is a popular technique in machine learning for dimensionality reduction. It is often used as a feature extraction technique as it helps to reduce the number of variables in a dataset by transforming the original features into a smaller set of uncorrelated features known as principal components. PCA can be used for feature extraction when the original features are highly correlated, or when the dimensionality of the dataset is high, making it difficult to perform computations on the original features.\n",
    "\n",
    "PCA works by identifying the directions in which the data varies the most, known as principal components. These principal components are a linear combination of the original features that explain the maximum amount of variance in the data. The first principal component captures the largest amount of variance in the data, followed by the second principal component, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c0f754",
   "metadata": {},
   "source": [
    "#### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580df054",
   "metadata": {},
   "source": [
    "In food Delivery databest whatever numerical is , i will applying following formula : \n",
    "    x - $x_{min}$ / $x_{max}$ - $x_{min}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e69d4",
   "metadata": {},
   "source": [
    "#### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb02ff5",
   "metadata": {},
   "source": [
    "In the context of predicting stock prices, the dataset may contain many features that are highly correlated with each other, such as different financial metrics for a company or market trends that affect multiple companies. PCA can be used to identify the most important features or variables that contribute the most to the variation in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2b4e8",
   "metadata": {},
   "source": [
    "#### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d8961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.21052631578947367, 0.47368421052631576, 0.7368421052631579, 1.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 =  [1, 5, 10, 15, 20]\n",
    "list2 = []\n",
    "for i in list1:\n",
    "    x = (i - min(list1)) / (max(list1)-min(list1))\n",
    "    list2.append(x)\n",
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380391c0",
   "metadata": {},
   "source": [
    "#### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4971a",
   "metadata": {},
   "source": [
    "i will use all components except gender because gender is categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe31bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
