{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4223035",
   "metadata": {},
   "source": [
    "#### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01213942",
   "metadata": {},
   "source": [
    "In machine learning algorithms, kernel functions are used to transform the input data into a higher dimensional space, where it becomes easier to separate classes using linear boundaries. The polynomial function is one type of kernel function commonly used in machine learning algorithms, along with others such as the Gaussian radial basis function (RBF) kernel.\n",
    "\n",
    "Polynomial kernel functions are used to map the input data into a higher dimensional space by computing all possible polynomial terms of the input features up to a certain degree. For example, a polynomial kernel of degree 2 for a two-dimensional input feature vector [x1, x2] would compute all possible combinations of polynomial terms up to degree 2, such as [x1^2, x2^2, x1x2], and then map these terms to a higher dimensional space.\n",
    "\n",
    "In other words, polynomial functions are used as the basis functions for the polynomial kernel, which transforms the input data into a higher dimensional space. The resulting transformed feature vectors can then be used to train a linear classifier, such as a support vector machine (SVM), to find a decision boundary that separates the classes.\n",
    "\n",
    "In summary, polynomial functions are used as the basis functions for the polynomial kernel, which is a type of kernel function used to transform the input data into a higher dimensional space. The resulting transformed feature vectors are then used to train a linear classifier to find a decision boundary that separates the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2bc0bd",
   "metadata": {},
   "source": [
    "#### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8727b862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features for visualization\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "poly_svm = SVC(kernel='poly', degree=3, C=1.0)\n",
    "poly_svm.fit(X_train, y_train)\n",
    "y_pred = poly_svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b3c26",
   "metadata": {},
   "source": [
    "#### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63f791",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), the value of epsilon controls the width of the epsilon-tube or the margin of error around the regression line. Increasing the value of epsilon allows more training examples to be within the margin of error, and as a result, the number of support vectors also increases.\n",
    "\n",
    "The number of support vectors in SVR depends on the distance between the training examples and the regression line. When the margin of error is widened by increasing the value of epsilon, more training examples are likely to fall within this margin, and thus more training examples become support vectors.\n",
    "\n",
    "In general, increasing the value of epsilon will result in a more flexible model that can fit a wider range of data points, but it may also lead to overfitting and reduced generalization performance. Therefore, it is important to carefully tune the value of epsilon to obtain the best trade-off between model complexity and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6df27",
   "metadata": {},
   "source": [
    "#### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef5bcb8",
   "metadata": {},
   "source": [
    "The choice of kernel function, C parameter, epsilon parameter, and gamma parameter can significantly affect the performance of Support Vector Regression (SVR). \n",
    "\n",
    "1. Kernel function: The kernel function determines the mapping of input data into a higher-dimensional feature space. The choice of kernel function affects the complexity and flexibility of the model. The commonly used kernel functions in SVR are linear, polynomial, and radial basis function (RBF). In general, the RBF kernel is more flexible and can fit a wider range of data, while the linear kernel is less flexible but can be faster and easier to interpret. The polynomial kernel can be useful when the relationship between input and output variables is nonlinear and the degree of the polynomial controls the complexity of the model.\n",
    "\n",
    "2. C parameter: The C parameter controls the trade-off between achieving a low training error and a low testing error. A high value of C means that the model will aim for a low training error, even if it results in a wider margin and more support vectors. A low value of C means that the model will prioritize a wider margin and fewer support vectors, even if it results in a higher training error. Increasing the value of C can lead to overfitting, while decreasing it can lead to underfitting. Therefore, it is important to carefully tune the value of C based on the data and problem at hand.\n",
    "\n",
    "3. Epsilon parameter: The epsilon parameter controls the width of the epsilon-tube or the margin of error around the regression line. Increasing the value of epsilon allows more training examples to be within the margin of error and as a result, the number of support vectors also increases. A larger value of epsilon can lead to a more flexible model, but it may also lead to overfitting.\n",
    "\n",
    "4. Gamma parameter: The gamma parameter controls the shape of the RBF kernel and the influence of each training example on the decision boundary. A high value of gamma means that the influence of each training example is limited to a small area, resulting in a more complex and flexible model. A low value of gamma means that the influence of each training example extends to a larger area, resulting in a smoother and simpler model. Increasing the value of gamma can lead to overfitting, while decreasing it can lead to underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3c36c",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:\n",
    "- Import the necessary libraries and load the dataset\n",
    "- Split the dataset into training and testing set\n",
    "- Preprocess the data using any technique of your choice (e.g. scaling, normaliMation\n",
    "- Create an instance of the SVC classifier and train it on the training data\n",
    "- use the trained classifier to predict the labels of the testing data\n",
    "- Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-score\n",
    "- Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performance\n",
    "- Train the tuned classifier on the entire dataset\n",
    "- Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f93c61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "df = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e95ea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd53ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e979af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7459f35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30), (426,), (143,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83fe26e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd85b1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8dd1aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  2]\n",
      " [ 3 86]]\n",
      "0.965034965034965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        54\n",
      "           1       0.98      0.97      0.97        89\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7263f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the hyperparameters using GridSearchCV\n",
    "parameters={\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e21c9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "classifier = GridSearchCV(SVC(),param_grid=parameters,cv=5,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da6209b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25bdb69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7fc6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3343991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  2]\n",
      " [ 3 86]]\n",
      "0.965034965034965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        54\n",
      "           1       0.98      0.97      0.97        89\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1cc41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
